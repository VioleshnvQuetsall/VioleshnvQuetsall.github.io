---
title: L2 正则
description: 机器学习--L2 正则下最优解变化
sitemap: false
hide_last_modified: true
categories: [ml]
tags: [L2-norm]
related_posts:
  - ''
---

0. this line will be replaced by the toc
{:toc}

### $$L2$$ 正则

$$
\begin{align*}
J=(\pmb X\pmb w-\pmb y)^T(\pmb X\pmb w-\pmb y)&\implies\pmb w=(\pmb X^T\pmb X)^{-1}\pmb X^T\pmb y\\
\widetilde J=(\pmb X\pmb w-\pmb y)^T(\pmb X\pmb w-\pmb y)+\frac\lambda2\pmb w^T\pmb w&\implies\pmb{\widetilde w}=(\pmb X^T\pmb X+\lambda\pmb I)^{-1}\pmb X^T\pmb y\\
\end{align*}
$$

---

一般的，损失函数为 $$J(\pmb w;\pmb X,\pmb y)$$，加入 $$L^2$$ 范数后 $$\widetilde J(\pmb w;\pmb X,\pmb y)=J(\pmb w;\pmb X,\pmb y)+\frac\lambda2\pmb w^T\pmb w$$；

在 $$\pmb w_0$$ 作近似 $$J(\pmb w)\approx J(\pmb w_0)+\nabla_{\pmb w}J^T(\pmb w_0)\cdot(\pmb w-\pmb w_0)+\frac12(\pmb w-\pmb w_0)^T\cdot\pmb H(\pmb w_0)\cdot(\pmb w-\pmb w_0)$$ ，如果 $$J$$ 为二次函数，则 $$\approx$$ 改为 $$=$$；

取梯度 $$\nabla_{\pmb w} J(\pmb w)=\nabla_{\pmb w}J(\pmb w_0)+\pmb H(\pmb w_0)\cdot(\pmb w-\pmb w_0)$$；

其中 $$\pmb H(\pmb w_0)$$ 为 $$J$$ 在 $$\pmb w_0$$ 的黑塞矩阵（Hessian matrix），$$\pmb H(\pmb w_0)_{i,j}={\partial^2J\over\partial \pmb w_0^{(i)}\partial\pmb w_0^{(j)}}$$。
$$
\begin{align*}
\begin{array}{ll}
\begin{array}{ll}
\text{let }\pmb w^*=\underset{\pmb w}{\arg\min}[J(\pmb w;\pmb X,\pmb y)],&\text{s.t. }\nabla_{\pmb w}J(\pmb w^*)=0
\end{array}\\[0.1cm]
\nabla_{\pmb w}\widetilde J(\pmb w)=\nabla_{\pmb w}J(\pmb w)+\lambda\pmb w=\nabla J(\pmb w_0)+\pmb H(\pmb w_0)\cdot(\pmb w-\pmb w_0)+\lambda\pmb w\\[0.5cm]
\begin{array}{ll}
\text{let }\pmb{\widetilde w}^*=\underset{\pmb w}{\arg\min}[\widetilde J(\pmb w;\pmb X,\pmb y)],&\text{s.t. }\nabla_{\pmb w}\widetilde J(\pmb{\widetilde w}^*)=0\\
\end{array}\\
\nabla_{\pmb w}\widetilde J(\pmb{\widetilde w}^*)=\nabla_{\pmb w}J(\pmb w_0)+\pmb H(\pmb w_0)\cdot(\pmb{\widetilde w}^*-\pmb w_0)+\lambda\pmb{\widetilde w}^*\\
\qquad\qquad\ \overset{\pmb w_0\leftarrow\pmb w^*}{===}0+\pmb H(\pmb w^*)\cdot(\pmb{\widetilde w}^*-\pmb w^*)+\lambda\pmb{\widetilde w}^*=0\\
\pmb{\widetilde w}^*=\left[\pmb H(\pmb w^*)+\lambda\pmb I\right]^{-1}\cdot\pmb H(\pmb w^*)\cdot\pmb w^*
\end{array}\\
\end{align*}
$$

$$
\begin{align*}
J&=(\pmb X\pmb w-\pmb y)^T(\pmb X\pmb w-\pmb y)\\
&={\pmb w}^T{\pmb X}^T\pmb X\pmb w-2{\pmb w}^T{\pmb X}^T\pmb y+{\pmb y}^T\pmb y\\
{\partial J\over\partial \pmb w}&=2{\pmb X}^T\pmb X\pmb w-2{\pmb X}^T\pmb y\\
{\partial\over\partial \pmb w}\left({\partial J\over\partial \pmb w}\right)^T&=2{\pmb X}^T\pmb X\\
\pmb H&=2{\pmb X}^T\pmb X\\
\pmb{\widetilde w}^*&=\left[\pmb H+\lambda\pmb I\right]^{-1}\cdot\pmb H\cdot\pmb w^*\\
&=\left[2{\pmb X}^T\pmb X+\lambda\pmb I\right]^{-1}\cdot2{\pmb X}^T\pmb X\cdot(\pmb X^T\pmb X)^{-1}\pmb X^T\pmb y\\
&=\left[{\pmb X}^T\pmb X+\frac\lambda2\pmb I\right]^{-1}\cdot\pmb X^T\pmb y
\end{align*}
$$

